# Session 11 Progress - CRITICAL BUG FIX: SFTTrainer Freezes LoRA Parameters

**Date:** 2025-11-25
**Duration:** ~1 hour
**Outcome:** MAJOR BUG DISCOVERED AND FIXED

---

## Executive Summary

We discovered and fixed a **critical bug** that caused **all LoRA parameters to be frozen** (trainable params = 0), making training completely ineffective. The validation loss was staying exactly the same (to 6 decimal places) across all evaluation steps because no weights were actually being updated.

---

## The Problem

### Symptoms Observed
1. **Validation loss completely flat**: `3.289622 â†’ 3.289622 â†’ 3.289622` (exactly the same)
2. **Mean token accuracy unchanged**: `0.425383 â†’ 0.425383 â†’ 0.425383`
3. **Training loss wiggled but didn't decrease**: Small random changes from dropout noise
4. **Warning message**: `UserWarning: None of the inputs have requires_grad=True. Gradients will be None`

### Verification
```python
# After SFTTrainer creation:
trainer.model.print_trainable_parameters()

# OUTPUT:
# trainable params: 0 || all params: 8,452,856,320 || trainable%: 0.0000
```

**Zero trainable parameters!** The model was essentially frozen.

---

## Root Cause Analysis

### The Original Code Flow (BUGGY)

```python
# Step 1: Load quantized model
model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_id,
    quantization_config=bnb_config,  # 4-bit QLoRA
    ...
)

# Step 2: Manually prepare for k-bit training (1st call)
model = prepare_model_for_kbit_training(model)

# Step 3: Manually apply LoRA
model = get_peft_model(model, lora_config)
# At this point: trainable params = 161,480,704 âœ“

# Step 4: Create SFTTrainer
trainer = SFTTrainer(
    model=model,  # Passing a PeftModel
    ...
    # NO peft_config - we thought this was correct
)
# At this point: trainable params = 0 âœ— (BUG!)
```

### What Happens Inside SFTTrainer

We traced through the TRL source code and found the bug:

**File: `trl/trainer/sft_trainer.py` (line 136-137)**
```python
if peft_config is not None or (is_peft_available() and isinstance(model, PeftModel)):
    model = prepare_peft_model(model, peft_config, args)
```

Since our model IS a `PeftModel` (we called `get_peft_model`), SFTTrainer calls `prepare_peft_model()`.

**File: `trl/models/utils.py` - `prepare_peft_model()` function**
```python
def prepare_peft_model(model, peft_config, args):
    # ...

    # Handle quantized models (QLoRA)
    is_qlora = getattr(model, "is_loaded_in_4bit", False) or getattr(model, "is_loaded_in_8bit", False)

    # ...

    # Prepare model for kbit training if needed
    if is_qlora and not is_sharded_qlora:
        model = prepare_model_for_kbit_training(  # â† SECOND CALL!
            model,
            use_gradient_checkpointing=args.gradient_checkpointing,
            ...
        )
```

### The Bug Mechanism

1. **We call** `prepare_model_for_kbit_training()` on base model â†’ OK, prepares for LoRA
2. **We call** `get_peft_model()` â†’ OK, adds LoRA adapters with 161M trainable params
3. **We pass PeftModel to SFTTrainer**
4. **SFTTrainer detects** it's a PeftModel loaded in 4-bit
5. **SFTTrainer calls** `prepare_model_for_kbit_training()` **AGAIN** on the PeftModel
6. **The second call** freezes ALL parameters, including the LoRA adapters!

### Why the Second Call Freezes Everything

`prepare_model_for_kbit_training()` iterates through ALL model parameters and:
- Sets `requires_grad = False` for quantized layers
- When called on a **base model**: Only freezes base weights, leaves room for LoRA
- When called on a **PeftModel**: Also freezes the LoRA adapter weights!

---

## Deep Dive: Understanding `prepare_model_for_kbit_training()`

### What Does This Function Actually Do?

This function from PEFT prepares a quantized model for training by:

1. **Freezing ALL parameters** - Sets `requires_grad=False` for everything
2. **Casting certain layers to float32** - For numerical stability
3. **Enabling gradient checkpointing** (optional) - To save memory

Here's the key logic (simplified):

```python
def prepare_model_for_kbit_training(model, ...):
    # Step 1: Freeze ALL parameters in the model
    for param in model.parameters():
        param.requires_grad = False  # â† Freezes EVERYTHING it finds

    # Step 2: Cast certain layers to float32 for stability
    for name, module in model.named_modules():
        if isinstance(module, (nn.LayerNorm, nn.Embedding)):
            module.to(torch.float32)

    return model
```

### Clarification: Quantized Layers vs Entire Model

In QLoRA (4-bit loading), **almost the entire model IS quantized**:

```
Model with load_in_4bit=True:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUANTIZED (4-bit):                         â”‚
â”‚  â”œâ”€â”€ All Linear layers (~99% of params)     â”‚
â”‚  â”‚   â”œâ”€â”€ q_proj, k_proj, v_proj, o_proj     â”‚
â”‚  â”‚   â”œâ”€â”€ gate_proj, up_proj, down_proj      â”‚
â”‚  â”‚   â””â”€â”€ ... (billions of parameters)       â”‚
â”‚                                             â”‚
â”‚  NOT QUANTIZED (kept in float32):           â”‚
â”‚  â”œâ”€â”€ LayerNorm layers                       â”‚
â”‚  â”œâ”€â”€ Embedding layers                       â”‚
â”‚  â””â”€â”€ (small fraction of params)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

So "quantized layers" â‰ˆ "nearly the entire model" in practice.

**However**, `prepare_model_for_kbit_training()` freezes **ALL parameters unconditionally** - not just quantized ones. The intent is: "Freeze everything now, add trainable LoRA adapters later."

### Visual Timeline: Why It Works on Base Model (Before LoRA)

```
BEFORE prepare_model_for_kbit_training():
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base Model (8B params)             â”‚
â”‚  â”œâ”€â”€ q_proj: 4-bit quantized        â”‚
â”‚  â”œâ”€â”€ k_proj: 4-bit quantized        â”‚
â”‚  â”œâ”€â”€ v_proj: 4-bit quantized        â”‚
â”‚  â””â”€â”€ ... (all quantized weights)    â”‚
â”‚                                     â”‚
â”‚  NO LoRA adapters yet!              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER prepare_model_for_kbit_training():
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base Model (8B params)             â”‚
â”‚  â”œâ”€â”€ q_proj: FROZEN â„ï¸              â”‚
â”‚  â”œâ”€â”€ k_proj: FROZEN â„ï¸              â”‚
â”‚  â”œâ”€â”€ v_proj: FROZEN â„ï¸              â”‚
â”‚  â””â”€â”€ ... (all FROZEN)               â”‚
â”‚                                     â”‚
â”‚  Still no LoRA - room to add them!  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER get_peft_model():
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PeftModel                          â”‚
â”‚  â”œâ”€â”€ base_model (FROZEN â„ï¸)         â”‚
â”‚  â”‚   â”œâ”€â”€ q_proj: FROZEN â„ï¸          â”‚
â”‚  â”‚   â””â”€â”€ ...                        â”‚
â”‚  â”‚                                  â”‚
â”‚  â””â”€â”€ LoRA adapters (NEW! ğŸ”¥)        â”‚
â”‚      â”œâ”€â”€ lora_A: requires_grad=True â”‚
â”‚      â”œâ”€â”€ lora_B: requires_grad=True â”‚
â”‚      â””â”€â”€ 161M trainable params!     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key insight**: When `get_peft_model()` adds LoRA adapters, it creates **NEW parameters** that weren't frozen because they didn't exist yet!

### Visual Timeline: Why It BREAKS on PeftModel (After LoRA)

```
BEFORE second prepare_model_for_kbit_training():
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PeftModel                          â”‚
â”‚  â”œâ”€â”€ base_model (FROZEN â„ï¸)         â”‚
â”‚  â”‚   â””â”€â”€ ...                        â”‚
â”‚  â”‚                                  â”‚
â”‚  â””â”€â”€ LoRA adapters (TRAINABLE ğŸ”¥)   â”‚
â”‚      â”œâ”€â”€ lora_A: requires_grad=True â”‚
â”‚      â”œâ”€â”€ lora_B: requires_grad=True â”‚
â”‚      â””â”€â”€ 161M trainable params!     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER second prepare_model_for_kbit_training():
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PeftModel                          â”‚
â”‚  â”œâ”€â”€ base_model (FROZEN â„ï¸)         â”‚
â”‚  â”‚   â””â”€â”€ ...                        â”‚
â”‚  â”‚                                  â”‚
â”‚  â””â”€â”€ LoRA adapters (NOW FROZEN! â„ï¸) â”‚
â”‚      â”œâ”€â”€ lora_A: requires_grad=Falseâ”‚  â† PROBLEM!
â”‚      â”œâ”€â”€ lora_B: requires_grad=Falseâ”‚  â† PROBLEM!
â”‚      â””â”€â”€ 0 trainable params!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The function doesn't know** the difference between:
- Base model weights (should be frozen)
- LoRA adapter weights (should stay trainable)

It just iterates through **ALL parameters** and sets `requires_grad=False`.

### Summary: Correct vs Buggy Flow

```
CORRECT FLOW (pass peft_config to SFTTrainer):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Model â†’ SFTTrainer handles everything internally
             â”œâ”€â”€ prepare_model_for_kbit_training() â† Called ONCE on base
             â””â”€â”€ get_peft_model() â† Adds LoRA AFTER freezing

Result: 161M trainable LoRA params âœ“


BUGGY FLOW (manual LoRA before SFTTrainer):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Model
    â†“
prepare_model_for_kbit_training() â† 1st call (OK)
    â†“
get_peft_model() â† Adds LoRA (161M trainable) âœ“
    â†“
Pass PeftModel to SFTTrainer
    â†“
SFTTrainer detects PeftModel + 4-bit
    â†“
prepare_model_for_kbit_training() â† 2nd call (BUG!)
    â†“
LoRA adapters FROZEN! 0 trainable params âœ—
```

---

## The Fix

### Solution: Let SFTTrainer Handle LoRA Setup

Instead of manually calling `prepare_model_for_kbit_training()` and `get_peft_model()`, we pass `peft_config` to SFTTrainer and let it handle everything properly.

### Code Changes

#### 1. Comment out manual `prepare_model_for_kbit_training` (lines 1433-1451)

```python
# =============================================================================
# COMMENTED OUT: Manual prepare_model_for_kbit_training
#
# BUG FIX (2025-11-25): SFTTrainer internally calls prepare_model_for_kbit_training
# when it detects QLoRA (see trl/models/utils.py:prepare_peft_model lines 23-29).
# If we call it manually AND pass a PeftModel to SFTTrainer, SFTTrainer calls it
# AGAIN on the PeftModel, which freezes ALL parameters including LoRA (trainable=0).
#
# Solution: Let SFTTrainer handle this by passing peft_config instead of
# manually creating a PeftModel.
#
# See: https://github.com/huggingface/trl/issues/3926
# =============================================================================
# print("=== Before prepare_model_for_kbit_training ===")
# _summarize_trainables(model)
# model = prepare_model_for_kbit_training(model)
# print("\nâœ… Model prepared for k-bit training")
# print("\n=== After prepare_model_for_kbit_training ===")
# _summarize_trainables(model)
```

#### 2. Comment out manual `get_peft_model` (lines 1502-1520)

```python
# =============================================================================
# COMMENTED OUT: Manual get_peft_model
#
# BUG FIX (2025-11-25): Same issue as prepare_model_for_kbit_training above.
# SFTTrainer will call get_peft_model internally when we pass peft_config.
# If we call it manually, SFTTrainer's prepare_peft_model will call
# prepare_model_for_kbit_training on our PeftModel, freezing all params.
#
# Solution: Pass lora_config to SFTTrainer via peft_config parameter instead.
# =============================================================================
# model = get_peft_model(model, lora_config)
# print("\nâœ… LoRA adapters attached to model")
# print("\n=== PEFT's parameter count (includes full base model) ===")
# model.print_trainable_parameters()
# print("\n=== After get_peft_model (LoRA attached) - Custom count ===")
# _summarize_trainables(model)

print("\nâœ… LoRA config created (will be applied by SFTTrainer)")
print("   Note: We pass peft_config to SFTTrainer instead of manually calling get_peft_model")
```

#### 3. Add `peft_config` to SFTTrainer (lines 2141-2181)

```python
# Create the trainer
# =============================================================================
# ORIGINAL COMMENTS (no longer applicable for TRL 0.22.0.dev0):
# # For TRL 0.12.0: We already manually:
# # 1. Called prepare_model_for_kbit_training()
# # 2. Applied get_peft_model() with LoRA config
# # So we DON'T pass peft_config to SFTTrainer (model is already a PEFT model)
# =============================================================================
#
# BUG FIX (2025-11-25): The above approach causes trainable params = 0 in TRL 0.22.0.dev0!
# SFTTrainer internally calls prepare_peft_model() which calls prepare_model_for_kbit_training()
# again on our PeftModel, freezing ALL parameters including LoRA adapters.
# Solution: Pass peft_config to SFTTrainer and let it handle LoRA setup.
# See: https://github.com/huggingface/trl/issues/3926

trainer = SFTTrainer(
    model=model,  # Base quantized model (NOT a PeftModel anymore)
    args=training_args,
    train_dataset=train_dataset_formatted,
    eval_dataset=eval_dataset_formatted,
    data_collator=collate_fn,
    processing_class=processor,
    peft_config=lora_config,  # BUG FIX: Let SFTTrainer handle LoRA setup properly
)

# DEBUG: Check if LoRA parameters are trainable after SFTTrainer creation
print("\n" + "="*60)
print("CHECKING TRAINABLE PARAMETERS AFTER SFTTrainer CREATION")
print("="*60)
trainer.model.print_trainable_parameters()
# If this shows 0 trainable params, the bug is still present
```

---

## Why Common Examples May Be Wrong

Many tutorials and examples online show this pattern:

```python
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)
trainer = SFTTrainer(model=model, ...)
```

This pattern **may have worked in older TRL versions** but is **broken in TRL 0.22.0.dev0** (and likely other recent versions). The behavior depends on:

| TRL Version | Behavior |
|-------------|----------|
| Older (0.4-0.8) | Often worked - didn't re-prepare PeftModel |
| 0.12+ | Added more QLoRA detection logic |
| 0.22.0.dev0 | Aggressively detects QLoRA and re-prepares, causing the bug |

---

## Environment Details

```
TRL version: 0.22.0.dev0
PEFT version: 0.17.1
Transformers version: 4.56.0.dev0
Model: Qwen2-VL (8B parameters)
Quantization: 4-bit QLoRA (NF4)
```

---

## Key Lessons Learned

1. **Always verify trainable parameters after trainer creation**
   ```python
   trainer.model.print_trainable_parameters()
   ```

2. **SFTTrainer has built-in QLoRA handling** - don't fight it, use it:
   ```python
   trainer = SFTTrainer(
       model=base_model,  # NOT PeftModel
       peft_config=lora_config,  # Let SFTTrainer handle it
       ...
   )
   ```

3. **Validation loss being exactly flat is a red flag** - it means nothing is being trained

4. **Training loss wiggling without decreasing** can be just dropout noise, not actual learning

5. **Library version changes can break previously working code** - always test after upgrades

---

## References

- GitHub Issue: https://github.com/huggingface/trl/issues/3926
- TRL Source: `trl/trainer/sft_trainer.py` lines 136-137
- TRL Source: `trl/models/utils.py` - `prepare_peft_model()` function

---

## Files Modified

- `fine_tuning_vlm_for_object_detection_trl.py`
- `fine_tuning_vlm_for_object_detection_trl.ipynb` (synced via jupytext)

---

## Expected Result After Fix

```
============================================================
CHECKING TRAINABLE PARAMETERS AFTER SFTTrainer CREATION
============================================================
trainable params: 161,480,704 || all params: 8,452,856,320 || trainable%: 1.9104
```

With trainable parameters restored, the validation loss should now change during training!

---

## Q&A: When is "trainable params: 0" Expected?

### Q: Is `trainable params: 0` ever expected?

**A: Yes, once â€” and no in your current situation.**

### âœ… Expected: Right after `prepare_model_for_kbit_training`, BEFORE LoRA

For QLoRA, the base 4-bit model is supposed to be frozen. So this sequence is **normal**:

```python
model = AutoModelForCausalLM.from_pretrained(
    ...,
    quantization_config=BitsAndBytesConfig(load_in_4bit=True)
)

model = prepare_model_for_kbit_training(model)

model.print_trainable_parameters()
# ğŸ‘‰ Often prints: trainable params: 0 (...), because LoRA not attached yet
```

At this point:
- **Base weights:** frozen (`requires_grad=False`) âœ…
- **LoRA:** not created yet, so also 0 âœ…

### âœ… Expected: After `get_peft_model` (LoRA attached)

Once you do:

```python
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
```

You should see **non-zero trainables** â€” the LoRA weights now have `requires_grad=True`:

```
=== After get_peft_model (LoRA attached) ===
trainable params: 161,480,704 || all params: 8,452,856,320 || trainable%: 1.9104
```

This is perfect! âœ…

### âŒ NOT Expected: After SFTTrainer creation

But then, after creating SFTTrainer, if you see:

```
After SFTTrainer creation:
trainable params: 0 || all params: 8,452,856,320 || trainable%: 0.0000
```

**This is NOT expected!** It means SFTTrainer has frozen everything, including the LoRA layers. That's why validation loss never moves.

### Summary Table: Expected Trainable Parameters at Each Stage

| Stage | Expected trainable params | Notes |
|-------|---------------------------|-------|
| After `from_pretrained` (4-bit) | 0 | Base model frozen by quantization |
| After `prepare_model_for_kbit_training` | 0 | Still no LoRA attached |
| After `get_peft_model` | ~161M (1.9%) | LoRA adapters now trainable âœ… |
| After `SFTTrainer` (with bug) | 0 | âŒ BUG - everything frozen |
| After `SFTTrainer` (fixed, with `peft_config`) | ~161M (1.9%) | âœ… LoRA adapters trainable |
